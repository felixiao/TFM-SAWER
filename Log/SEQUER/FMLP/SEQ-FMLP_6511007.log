-----------------------------------ARGUMENTS------------------------------------
model_name                               fmlpeter
dataset                                  amazon-movies
fold                                     0
cuda                                     True
test                                     False
no_generate                              False
log_interval                             4
seed                                     1111
no_train                                 True
log_file                                 ./Log/SEQ-FMLP_PETER.log
emsize                                   512
nhead                                    2
nhid                                     2048
nlayers                                  2
dropout                                  0.2
lr                                       1.0
clip_norm                                1.0
epochs                                   100
batch_size                               128
log_interval                             4
vocab_size                               20000
endure_times                             5
rating_reg                               0.1
context_reg                              1.0
text_reg                                 1.0
item_reg                                 0.1
hist_len                                 20
user_len                                 0
item_len                                 1
use_feature                              True
seq_mode                                 2
peter_mask                               True
seq_prediction                           True
context_prediction                       True
rating_prediction                        True
nextitem_prediction                      False
-----------------------------------ARGUMENTS------------------------------------
train len:359303
FMLPETER Mask: Len=38
=========================================================================================
bos:torch.Size([1, 128]),text:torch.Size([2, 128])
word_prob:torch.Size([1, 128, 20004]), word_idx:torch.Size([1, 128])
word_prob:torch.Size([2, 128, 20004]), word_idx:torch.Size([2, 128])
word_prob:torch.Size([4, 128, 20004]), word_idx:torch.Size([4, 128])
word_prob:torch.Size([8, 128, 20004]), word_idx:torch.Size([8, 128])
word_prob:torch.Size([16, 128, 20004]), word_idx:torch.Size([16, 128])
train len:359303
FMLPETER Mask: Len=38
=========================================================================================
bos:torch.Size([1, 128]),text:torch.Size([2, 128])
word_prob:torch.Size([1, 128, 20004]), word_idx:torch.Size([1, 128])
word_prob:torch.Size([2, 128, 20004]), word_idx:torch.Size([2, 128])
word_prob:torch.Size([4, 128, 20004]), word_idx:torch.Size([4, 128])
word_prob:torch.Size([8, 128, 20004]), word_idx:torch.Size([8, 128])
word_prob:torch.Size([16, 128, 20004]), word_idx:torch.Size([16, 128])
train len:359303
FMLPETER Mask: Len=38
=========================================================================================
bos:torch.Size([1, 128]),text:torch.Size([2, 128])
word_prob:torch.Size([1, 128, 20004]), word_idx:torch.Size([1, 128])
word_prob:torch.Size([2, 128, 20004]), word_idx:torch.Size([2, 128])
word_prob:torch.Size([4, 128, 20004]), word_idx:torch.Size([4, 128])
word_prob:torch.Size([8, 128, 20004]), word_idx:torch.Size([8, 128])
word_prob:torch.Size([16, 128, 20004]), word_idx:torch.Size([16, 128])
train len:359303
FMLPETER Mask: Len=38
=========================================================================================
bos:torch.Size([1, 128]),text:torch.Size([2, 128])
word_prob:torch.Size([1, 128, 20004]), word_idx:torch.Size([1, 128])
word_prob:torch.Size([2, 128, 20004]), word_idx:torch.Size([2, 128])
word_prob:torch.Size([4, 128, 20004]), word_idx:torch.Size([4, 128])
word_prob:torch.Size([8, 128, 20004]), word_idx:torch.Size([8, 128])
word_prob:torch.Size([16, 128, 20004]), word_idx:torch.Size([16, 128])
