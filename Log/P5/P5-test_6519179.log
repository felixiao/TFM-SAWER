['rating_loss', 'sequential_loss', 'explanation_loss', 'review_loss', 'traditional_loss']
Process Launching at GPU 0
{'distributed': False, 'multiGPU': False, 'fp16': True, 'train': 'beauty', 'valid': 'beauty', 'test': 'beauty', 'batch_size': 100, 'optim': 'adamw', 'warmup_ratio': 0.05, 'lr': 0.001, 'num_workers': 4, 'clip_grad_norm': 1.0, 'losses': 'rating,sequential,explanation,review,traditional', 'backbone': 't5-small', 'output': '.P5/snap/beauty-small', 'epoch': 10, 'local_rank': 0, 'comment': '', 'train_topk': -1, 'valid_topk': -1, 'dropout': 0.1, 'tokenizer': 'p5', 'max_text_length': 512, 'do_lower_case': False, 'word_mask_rate': 0.15, 'gen_max_length': 64, 'weight_decay': 0.01, 'adam_eps': 1e-06, 'gradient_accumulation_steps': 1, 'seed': 1111, 'whole_word_embed': True, 'world_size': 1, 'LOSSES_NAME': ['rating_loss', 'sequential_loss', 'explanation_loss', 'review_loss', 'traditional_loss', 'total_loss'], 'gpu': 0, 'rank': 0, 'run_name': 'Jan14_02-59_GPU1_beauty_t5-small_ratingsequentialexplanationreviewtraditional'}
<class 'tokenization.P5Tokenizer'> t5-small
Building Model at GPU 0
Model loaded from  ./P5/snap/beauty-small.pth
<All keys matched successfully>
Data sources:  ['beauty']
compute_datum_info
224
no
['rating_loss', 'sequential_loss', 'explanation_loss', 'review_loss', 'traditional_loss']
Process Launching at GPU 0
{'distributed': False, 'multiGPU': False, 'fp16': True, 'train': 'beauty', 'valid': 'beauty', 'test': 'beauty', 'batch_size': 100, 'optim': 'adamw', 'warmup_ratio': 0.05, 'lr': 0.001, 'num_workers': 4, 'clip_grad_norm': 1.0, 'losses': 'rating,sequential,explanation,review,traditional', 'backbone': 't5-small', 'output': '.P5/snap/beauty-small', 'epoch': 10, 'local_rank': 0, 'comment': '', 'train_topk': -1, 'valid_topk': -1, 'dropout': 0.1, 'tokenizer': 'p5', 'max_text_length': 512, 'do_lower_case': False, 'word_mask_rate': 0.15, 'gen_max_length': 64, 'weight_decay': 0.01, 'adam_eps': 1e-06, 'gradient_accumulation_steps': 1, 'seed': 1111, 'whole_word_embed': True, 'world_size': 1, 'LOSSES_NAME': ['rating_loss', 'sequential_loss', 'explanation_loss', 'review_loss', 'traditional_loss', 'total_loss'], 'gpu': 0, 'rank': 0, 'run_name': 'Jan14_03-31_GPU1_beauty_t5-small_ratingsequentialexplanationreviewtraditional'}
<class 'tokenization.P5Tokenizer'> t5-small
Building Model at GPU 0
Model loaded from  ./P5/snap/beauty-small.pth
<All keys matched successfully>
Data sources:  ['beauty']
compute_datum_info
135
BLEU-1  8.7197
BLEU-4  5.4090
rouge_1/f_score 68.3171
rouge_1/r_score 57.4185
rouge_1/p_score 88.4772
rouge_2/f_score 36.8727
rouge_2/r_score 27.9985
rouge_2/p_score 66.5378
rouge_l/f_score 30.6910
rouge_l/r_score 29.5964
rouge_l/p_score 76.2587
Data sources:  ['beauty']
compute_datum_info
224
['rating_loss', 'sequential_loss', 'explanation_loss', 'review_loss', 'traditional_loss']
Process Launching at GPU 0
{'distributed': False, 'multiGPU': False, 'fp16': True, 'train': 'beauty', 'valid': 'beauty', 'test': 'beauty', 'batch_size': 100, 'optim': 'adamw', 'warmup_ratio': 0.05, 'lr': 0.001, 'num_workers': 4, 'clip_grad_norm': 1.0, 'losses': 'rating,sequential,explanation,review,traditional', 'backbone': 't5-small', 'output': '.P5/snap/beauty-small', 'epoch': 10, 'local_rank': 0, 'comment': '', 'train_topk': -1, 'valid_topk': -1, 'dropout': 0.1, 'tokenizer': 'p5', 'max_text_length': 512, 'do_lower_case': False, 'word_mask_rate': 0.15, 'gen_max_length': 64, 'weight_decay': 0.01, 'adam_eps': 1e-06, 'gradient_accumulation_steps': 1, 'seed': 1111, 'whole_word_embed': True, 'world_size': 1, 'LOSSES_NAME': ['rating_loss', 'sequential_loss', 'explanation_loss', 'review_loss', 'traditional_loss', 'total_loss'], 'gpu': 0, 'rank': 0, 'run_name': 'Jan14_03-37_GPU1_beauty_t5-small_ratingsequentialexplanationreviewtraditional'}
<class 'tokenization.P5Tokenizer'> t5-small
Building Model at GPU 0
Model loaded from  ./P5/snap/beauty-small.pth
<All keys matched successfully>
Data sources:  ['beauty']
compute_datum_info
135
BLEU-1  8.7197
BLEU-4  5.4090
rouge_1/f_score 68.3171
rouge_1/r_score 57.4185
rouge_1/p_score 88.4772
rouge_2/f_score 36.8727
rouge_2/r_score 27.9985
rouge_2/p_score 66.5378
rouge_l/f_score 30.6910
rouge_l/r_score 29.5964
rouge_l/p_score 76.2587
Data sources:  ['beauty']
compute_datum_info
224
['rating_loss', 'sequential_loss', 'explanation_loss', 'review_loss', 'traditional_loss']
Process Launching at GPU 0
{'distributed': False, 'multiGPU': False, 'fp16': True, 'train': 'beauty', 'valid': 'beauty', 'test': 'beauty', 'batch_size': 100, 'optim': 'adamw', 'warmup_ratio': 0.05, 'lr': 0.001, 'num_workers': 4, 'clip_grad_norm': 1.0, 'losses': 'rating,sequential,explanation,review,traditional', 'backbone': 't5-small', 'output': '.P5/snap/beauty-small', 'epoch': 10, 'local_rank': 0, 'comment': '', 'train_topk': -1, 'valid_topk': -1, 'dropout': 0.1, 'tokenizer': 'p5', 'max_text_length': 512, 'do_lower_case': False, 'word_mask_rate': 0.15, 'gen_max_length': 64, 'weight_decay': 0.01, 'adam_eps': 1e-06, 'gradient_accumulation_steps': 1, 'seed': 1111, 'whole_word_embed': True, 'world_size': 1, 'LOSSES_NAME': ['rating_loss', 'sequential_loss', 'explanation_loss', 'review_loss', 'traditional_loss', 'total_loss'], 'gpu': 0, 'rank': 0, 'run_name': 'Jan14_03-43_GPU1_beauty_t5-small_ratingsequentialexplanationreviewtraditional'}
<class 'tokenization.P5Tokenizer'> t5-small
Building Model at GPU 0
Model loaded from  ./P5/snap/beauty-small.pth
<All keys matched successfully>
Data sources:  ['beauty']
compute_datum_info
135
BLEU-1  8.7197
BLEU-4  5.4090
rouge_1/f_score 68.3171
rouge_1/r_score 57.4185
rouge_1/p_score 88.4772
rouge_2/f_score 36.8727
rouge_2/r_score 27.9985
rouge_2/p_score 66.5378
rouge_l/f_score 30.6910
rouge_l/r_score 29.5964
rouge_l/p_score 76.2587
Data sources:  ['beauty']
compute_datum_info
224
